{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medIncome</th>\n",
       "      <th>pctWWage</th>\n",
       "      <th>perCapInc</th>\n",
       "      <th>whitePerCap</th>\n",
       "      <th>blackPerCap</th>\n",
       "      <th>indianPerCap</th>\n",
       "      <th>asianPerCap</th>\n",
       "      <th>otherPerCap</th>\n",
       "      <th>HispPerCap</th>\n",
       "      <th>pctPopUnderPov</th>\n",
       "      <th>...</th>\n",
       "      <th>Log_burglPerPop</th>\n",
       "      <th>Log_larcenies</th>\n",
       "      <th>Log_larcPerPop</th>\n",
       "      <th>Log_autoTheft</th>\n",
       "      <th>Log_autoTheftPerPop</th>\n",
       "      <th>Log_arsons</th>\n",
       "      <th>Log_arsonsPerPop</th>\n",
       "      <th>Log_ViolentCrimesPerPop</th>\n",
       "      <th>Log_nonViolPerPop</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.876345</td>\n",
       "      <td>1.600432</td>\n",
       "      <td>0.941602</td>\n",
       "      <td>1.159390</td>\n",
       "      <td>0.415994</td>\n",
       "      <td>-0.093158</td>\n",
       "      <td>0.039099</td>\n",
       "      <td>0.835051</td>\n",
       "      <td>0.563030</td>\n",
       "      <td>-0.420409</td>\n",
       "      <td>...</td>\n",
       "      <td>1.014704</td>\n",
       "      <td>1.968360</td>\n",
       "      <td>0.007233</td>\n",
       "      <td>2.586872</td>\n",
       "      <td>0.764607</td>\n",
       "      <td>2.145875</td>\n",
       "      <td>0.820506</td>\n",
       "      <td>1.989888</td>\n",
       "      <td>0.680567</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.234794</td>\n",
       "      <td>1.437346</td>\n",
       "      <td>1.008933</td>\n",
       "      <td>1.308139</td>\n",
       "      <td>0.480702</td>\n",
       "      <td>-0.121228</td>\n",
       "      <td>-0.063869</td>\n",
       "      <td>0.771022</td>\n",
       "      <td>0.448013</td>\n",
       "      <td>-0.640405</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.978673</td>\n",
       "      <td>-0.417671</td>\n",
       "      <td>-0.795302</td>\n",
       "      <td>0.100167</td>\n",
       "      <td>0.114909</td>\n",
       "      <td>-0.161035</td>\n",
       "      <td>-0.297702</td>\n",
       "      <td>-0.054134</td>\n",
       "      <td>0.062051</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.197109</td>\n",
       "      <td>1.260783</td>\n",
       "      <td>-0.170482</td>\n",
       "      <td>0.098767</td>\n",
       "      <td>-0.179320</td>\n",
       "      <td>-0.301121</td>\n",
       "      <td>-0.512889</td>\n",
       "      <td>0.059712</td>\n",
       "      <td>-0.383929</td>\n",
       "      <td>0.073097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.754678</td>\n",
       "      <td>0.180323</td>\n",
       "      <td>-0.009341</td>\n",
       "      <td>0.625712</td>\n",
       "      <td>0.792283</td>\n",
       "      <td>0.867172</td>\n",
       "      <td>1.107332</td>\n",
       "      <td>-0.999713</td>\n",
       "      <td>-1.577354</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.759653</td>\n",
       "      <td>-0.246070</td>\n",
       "      <td>-0.533620</td>\n",
       "      <td>-0.111510</td>\n",
       "      <td>-0.827913</td>\n",
       "      <td>0.023760</td>\n",
       "      <td>0.036641</td>\n",
       "      <td>0.965798</td>\n",
       "      <td>-0.207766</td>\n",
       "      <td>1.060108</td>\n",
       "      <td>...</td>\n",
       "      <td>1.536764</td>\n",
       "      <td>1.247670</td>\n",
       "      <td>1.088329</td>\n",
       "      <td>1.324566</td>\n",
       "      <td>1.185399</td>\n",
       "      <td>0.976763</td>\n",
       "      <td>0.713426</td>\n",
       "      <td>1.064480</td>\n",
       "      <td>0.492163</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.860033</td>\n",
       "      <td>-0.837759</td>\n",
       "      <td>-0.739429</td>\n",
       "      <td>-0.833392</td>\n",
       "      <td>-0.602023</td>\n",
       "      <td>-0.510427</td>\n",
       "      <td>1.127371</td>\n",
       "      <td>0.222923</td>\n",
       "      <td>-1.085397</td>\n",
       "      <td>0.687006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.449002</td>\n",
       "      <td>-0.219521</td>\n",
       "      <td>0.602244</td>\n",
       "      <td>-0.377621</td>\n",
       "      <td>0.468178</td>\n",
       "      <td>-0.542571</td>\n",
       "      <td>-0.125260</td>\n",
       "      <td>1.064480</td>\n",
       "      <td>0.492163</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   medIncome  pctWWage  perCapInc  whitePerCap  blackPerCap  indianPerCap  \\\n",
       "0   0.876345  1.600432   0.941602     1.159390     0.415994     -0.093158   \n",
       "1   1.234794  1.437346   1.008933     1.308139     0.480702     -0.121228   \n",
       "2  -0.197109  1.260783  -0.170482     0.098767    -0.179320     -0.301121   \n",
       "3  -0.759653 -0.246070  -0.533620    -0.111510    -0.827913      0.023760   \n",
       "4  -0.860033 -0.837759  -0.739429    -0.833392    -0.602023     -0.510427   \n",
       "\n",
       "   asianPerCap  otherPerCap  HispPerCap  pctPopUnderPov  ...  Log_burglPerPop  \\\n",
       "0     0.039099     0.835051    0.563030       -0.420409  ...         1.014704   \n",
       "1    -0.063869     0.771022    0.448013       -0.640405  ...        -0.978673   \n",
       "2    -0.512889     0.059712   -0.383929        0.073097  ...         0.754678   \n",
       "3     0.036641     0.965798   -0.207766        1.060108  ...         1.536764   \n",
       "4     1.127371     0.222923   -1.085397        0.687006  ...         0.449002   \n",
       "\n",
       "   Log_larcenies  Log_larcPerPop  Log_autoTheft  Log_autoTheftPerPop  \\\n",
       "0       1.968360        0.007233       2.586872             0.764607   \n",
       "1      -0.417671       -0.795302       0.100167             0.114909   \n",
       "2       0.180323       -0.009341       0.625712             0.792283   \n",
       "3       1.247670        1.088329       1.324566             1.185399   \n",
       "4      -0.219521        0.602244      -0.377621             0.468178   \n",
       "\n",
       "   Log_arsons  Log_arsonsPerPop  Log_ViolentCrimesPerPop  Log_nonViolPerPop  \\\n",
       "0    2.145875          0.820506                 1.989888           0.680567   \n",
       "1   -0.161035         -0.297702                -0.054134           0.062051   \n",
       "2    0.867172          1.107332                -0.999713          -1.577354   \n",
       "3    0.976763          0.713426                 1.064480           0.492163   \n",
       "4   -0.542571         -0.125260                 1.064480           0.492163   \n",
       "\n",
       "   State  \n",
       "0     AK  \n",
       "1     AK  \n",
       "2     AK  \n",
       "3     AL  \n",
       "4     AL  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"processed_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.drop(['Log_NumInShelters', 'Log_NumStreet', 'Log_murders', 'Log_murdPerPop', 'State', 'Log_nonViolPerPop'], axis=1)\n",
    "df_new.head()\n",
    "df_new.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Features and Label and set train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_new.drop(['Log_ViolentCrimesPerPop'], axis=1)\n",
    "y = df_new['Log_ViolentCrimesPerPop']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 424)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import, initiate and fit random forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.433019480438791"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # create regressor object \n",
    "    \n",
    "from sklearn.ensemble import RandomForestRegressor     \n",
    "regressor = RandomForestRegressor(n_estimators = 100, random_state = 0) \n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = regressor.predict(X_test)\n",
    "r2_score(y_test,y_pred_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model with 10 folds cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40581416724892927\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# clf = RandomForestRegressor()\n",
    " #Initialize with whatever parameters you want to\n",
    "\n",
    "print(np.mean(cross_val_score(RandomForestRegressor(), X, y, cv=10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search to tune random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [50, 71, 92, 114, 135, 157, 178, 200], 'max_features': ['auto', 'sqrt'], 'max_depth': [5, 9, 13, 17, 21, 25, 30, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 50, stop = 200, num = 8)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5, 30, num = 7)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   32.6s finished\n"
     ]
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "y_pred_best = rf_random.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best features for random forest are: {'n_estimators': 92, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 13, 'bootstrap': True}\n",
      "R2 score: 0.5153508939246441\n",
      "Improvement from untuned random forest: 2.4588250455359284 %\n"
     ]
    }
   ],
   "source": [
    "print('best features for random forest are:', rf_random.best_params_)\n",
    "print(\"R2 score:\", r2_score(y_test,y_pred_best))\n",
    "print(\"Improvement from untuned random forest:\", (r2_score(y_test,y_pred_best) - r2_score(y_test,y_pred_rf)) * 100,'%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   30.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   27.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:   14.0s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   28.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   26.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   26.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   26.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   26.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   29.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   26.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   28.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.453504155240001\n"
     ]
    }
   ],
   "source": [
    " #Initialize with whatever parameters you want to\n",
    "\n",
    "print(np.mean(cross_val_score(rf_random, X_train, y_train, cv=10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate and test Bagging Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4824129010078564"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "bagging_regressor = BaggingRegressor() \n",
    "bagging_regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred_bg = bagging_regressor.predict(X_test)\n",
    "r2_score(y_test,y_pred_bg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39284335458578196\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(cross_val_score(BaggingRegressor(), X_train, y_train, cv=10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate and test  XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the dataset into an optimized data structure called Dmatrix that XGBoost supports\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:56:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.2.0/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:56:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.2.0/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5071993194396187"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "# convert the dataset into an optimized data structure called Dmatrix that XGBoost supports\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 3, alpha = 10, n_estimators = 200)\n",
    "xg_reg.fit(X_train,y_train)\n",
    "y_pred_xg = xg_reg.predict(X_test)\n",
    "r2_score(y_test,y_pred_xg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:04:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.2.0/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:04:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.2.0/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:04:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.2.0/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:04:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.2.0/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:04:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.2.0/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:04:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.2.0/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:04:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.2.0/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:04:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.2.0/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:04:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.2.0/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:04:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.2.0/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:04:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.2.0/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:04:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.2.0/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:04:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.2.0/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:04:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.2.0/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:04:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.2.0/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:04:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.2.0/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:04:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.2.0/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:04:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.2.0/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:04:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.2.0/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:04:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.2.0/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "0.43288165881676255\n"
     ]
    }
   ],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 3, alpha = 10, n_estimators = 200)\n",
    "\n",
    "print(np.mean(cross_val_score(xg_reg, X_train, y_train, cv=10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate and test LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43805073775107417"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "LGBM_reg = LGBMRegressor()\n",
    "LGBM_reg.fit(X_train,y_train)\n",
    "y_pred_lgbm = LGBM_reg.predict(X_test)\n",
    "r2_score(y_test,y_pred_lgbm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39696509424337617\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(cross_val_score(LGBMRegressor(), X_train, y_train, cv=10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate and test AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39539677546759666"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "ada_rgr = AdaBoostRegressor()\n",
    "ada_rgr.fit(X_train,y_train)\n",
    "y_pred_ada = ada_rgr.predict(X_test)\n",
    "r2_score(y_test,y_pred_ada)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35517734968924747\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(cross_val_score(AdaBoostRegressor(), X_train, y_train, cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
