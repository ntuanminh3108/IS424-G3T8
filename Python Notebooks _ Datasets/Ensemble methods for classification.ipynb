{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medIncome</th>\n",
       "      <th>pctWWage</th>\n",
       "      <th>perCapInc</th>\n",
       "      <th>whitePerCap</th>\n",
       "      <th>blackPerCap</th>\n",
       "      <th>indianPerCap</th>\n",
       "      <th>asianPerCap</th>\n",
       "      <th>otherPerCap</th>\n",
       "      <th>HispPerCap</th>\n",
       "      <th>pctPopUnderPov</th>\n",
       "      <th>...</th>\n",
       "      <th>Log_burglPerPop</th>\n",
       "      <th>Log_larcenies</th>\n",
       "      <th>Log_larcPerPop</th>\n",
       "      <th>Log_autoTheft</th>\n",
       "      <th>Log_autoTheftPerPop</th>\n",
       "      <th>Log_arsons</th>\n",
       "      <th>Log_arsonsPerPop</th>\n",
       "      <th>Log_ViolentCrimesPerPop</th>\n",
       "      <th>Log_nonViolPerPop</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.876345</td>\n",
       "      <td>1.600432</td>\n",
       "      <td>0.941602</td>\n",
       "      <td>1.159390</td>\n",
       "      <td>0.415994</td>\n",
       "      <td>-0.093158</td>\n",
       "      <td>0.039099</td>\n",
       "      <td>0.835051</td>\n",
       "      <td>0.563030</td>\n",
       "      <td>-0.420409</td>\n",
       "      <td>...</td>\n",
       "      <td>1.014704</td>\n",
       "      <td>1.968360</td>\n",
       "      <td>0.007233</td>\n",
       "      <td>2.586872</td>\n",
       "      <td>0.764607</td>\n",
       "      <td>2.145875</td>\n",
       "      <td>0.820506</td>\n",
       "      <td>1.989888</td>\n",
       "      <td>0.680567</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.234794</td>\n",
       "      <td>1.437346</td>\n",
       "      <td>1.008933</td>\n",
       "      <td>1.308139</td>\n",
       "      <td>0.480702</td>\n",
       "      <td>-0.121228</td>\n",
       "      <td>-0.063869</td>\n",
       "      <td>0.771022</td>\n",
       "      <td>0.448013</td>\n",
       "      <td>-0.640405</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.978673</td>\n",
       "      <td>-0.417671</td>\n",
       "      <td>-0.795302</td>\n",
       "      <td>0.100167</td>\n",
       "      <td>0.114909</td>\n",
       "      <td>-0.161035</td>\n",
       "      <td>-0.297702</td>\n",
       "      <td>-0.054134</td>\n",
       "      <td>0.062051</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.197109</td>\n",
       "      <td>1.260783</td>\n",
       "      <td>-0.170482</td>\n",
       "      <td>0.098767</td>\n",
       "      <td>-0.179320</td>\n",
       "      <td>-0.301121</td>\n",
       "      <td>-0.512889</td>\n",
       "      <td>0.059712</td>\n",
       "      <td>-0.383929</td>\n",
       "      <td>0.073097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.754678</td>\n",
       "      <td>0.180323</td>\n",
       "      <td>-0.009341</td>\n",
       "      <td>0.625712</td>\n",
       "      <td>0.792283</td>\n",
       "      <td>0.867172</td>\n",
       "      <td>1.107332</td>\n",
       "      <td>-0.999713</td>\n",
       "      <td>-1.577354</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.759653</td>\n",
       "      <td>-0.246070</td>\n",
       "      <td>-0.533620</td>\n",
       "      <td>-0.111510</td>\n",
       "      <td>-0.827913</td>\n",
       "      <td>0.023760</td>\n",
       "      <td>0.036641</td>\n",
       "      <td>0.965798</td>\n",
       "      <td>-0.207766</td>\n",
       "      <td>1.060108</td>\n",
       "      <td>...</td>\n",
       "      <td>1.536764</td>\n",
       "      <td>1.247670</td>\n",
       "      <td>1.088329</td>\n",
       "      <td>1.324566</td>\n",
       "      <td>1.185399</td>\n",
       "      <td>0.976763</td>\n",
       "      <td>0.713426</td>\n",
       "      <td>1.064480</td>\n",
       "      <td>0.492163</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.860033</td>\n",
       "      <td>-0.837759</td>\n",
       "      <td>-0.739429</td>\n",
       "      <td>-0.833392</td>\n",
       "      <td>-0.602023</td>\n",
       "      <td>-0.510427</td>\n",
       "      <td>1.127371</td>\n",
       "      <td>0.222923</td>\n",
       "      <td>-1.085397</td>\n",
       "      <td>0.687006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.449002</td>\n",
       "      <td>-0.219521</td>\n",
       "      <td>0.602244</td>\n",
       "      <td>-0.377621</td>\n",
       "      <td>0.468178</td>\n",
       "      <td>-0.542571</td>\n",
       "      <td>-0.125260</td>\n",
       "      <td>1.064480</td>\n",
       "      <td>0.492163</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   medIncome  pctWWage  perCapInc  whitePerCap  blackPerCap  indianPerCap  \\\n",
       "0   0.876345  1.600432   0.941602     1.159390     0.415994     -0.093158   \n",
       "1   1.234794  1.437346   1.008933     1.308139     0.480702     -0.121228   \n",
       "2  -0.197109  1.260783  -0.170482     0.098767    -0.179320     -0.301121   \n",
       "3  -0.759653 -0.246070  -0.533620    -0.111510    -0.827913      0.023760   \n",
       "4  -0.860033 -0.837759  -0.739429    -0.833392    -0.602023     -0.510427   \n",
       "\n",
       "   asianPerCap  otherPerCap  HispPerCap  pctPopUnderPov  ...  Log_burglPerPop  \\\n",
       "0     0.039099     0.835051    0.563030       -0.420409  ...         1.014704   \n",
       "1    -0.063869     0.771022    0.448013       -0.640405  ...        -0.978673   \n",
       "2    -0.512889     0.059712   -0.383929        0.073097  ...         0.754678   \n",
       "3     0.036641     0.965798   -0.207766        1.060108  ...         1.536764   \n",
       "4     1.127371     0.222923   -1.085397        0.687006  ...         0.449002   \n",
       "\n",
       "   Log_larcenies  Log_larcPerPop  Log_autoTheft  Log_autoTheftPerPop  \\\n",
       "0       1.968360        0.007233       2.586872             0.764607   \n",
       "1      -0.417671       -0.795302       0.100167             0.114909   \n",
       "2       0.180323       -0.009341       0.625712             0.792283   \n",
       "3       1.247670        1.088329       1.324566             1.185399   \n",
       "4      -0.219521        0.602244      -0.377621             0.468178   \n",
       "\n",
       "   Log_arsons  Log_arsonsPerPop  Log_ViolentCrimesPerPop  Log_nonViolPerPop  \\\n",
       "0    2.145875          0.820506                 1.989888           0.680567   \n",
       "1   -0.161035         -0.297702                -0.054134           0.062051   \n",
       "2    0.867172          1.107332                -0.999713          -1.577354   \n",
       "3    0.976763          0.713426                 1.064480           0.492163   \n",
       "4   -0.542571         -0.125260                 1.064480           0.492163   \n",
       "\n",
       "   State  \n",
       "0     AK  \n",
       "1     AK  \n",
       "2     AK  \n",
       "3     AL  \n",
       "4     AL  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"processed_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.drop(['Log_NumInShelters', 'Log_NumStreet', 'Log_murders', 'Log_murdPerPop', 'State', 'Log_nonViolPerPop'], axis=1)\n",
    "df_new.head()\n",
    "df_new.dropna(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create labels for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_or_low(rate):\n",
    "    median_rate = df_new['Log_ViolentCrimesPerPop'].median()\n",
    "    if rate<median_rate: \n",
    "        return 0\n",
    "    else: \n",
    "        return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['isViolentCrimePerPopHigh'] = df_new['Log_ViolentCrimesPerPop'].apply(high_or_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medIncome</th>\n",
       "      <th>pctWWage</th>\n",
       "      <th>perCapInc</th>\n",
       "      <th>whitePerCap</th>\n",
       "      <th>blackPerCap</th>\n",
       "      <th>indianPerCap</th>\n",
       "      <th>asianPerCap</th>\n",
       "      <th>otherPerCap</th>\n",
       "      <th>HispPerCap</th>\n",
       "      <th>pctPopUnderPov</th>\n",
       "      <th>...</th>\n",
       "      <th>Log_burglaries</th>\n",
       "      <th>Log_burglPerPop</th>\n",
       "      <th>Log_larcenies</th>\n",
       "      <th>Log_larcPerPop</th>\n",
       "      <th>Log_autoTheft</th>\n",
       "      <th>Log_autoTheftPerPop</th>\n",
       "      <th>Log_arsons</th>\n",
       "      <th>Log_arsonsPerPop</th>\n",
       "      <th>Log_ViolentCrimesPerPop</th>\n",
       "      <th>isViolentCrimePerPopHigh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.876345</td>\n",
       "      <td>1.600432</td>\n",
       "      <td>0.941602</td>\n",
       "      <td>1.159390</td>\n",
       "      <td>0.415994</td>\n",
       "      <td>-0.093158</td>\n",
       "      <td>0.039099</td>\n",
       "      <td>0.835051</td>\n",
       "      <td>0.563030</td>\n",
       "      <td>-0.420409</td>\n",
       "      <td>...</td>\n",
       "      <td>2.256699</td>\n",
       "      <td>1.014704</td>\n",
       "      <td>1.968360</td>\n",
       "      <td>0.007233</td>\n",
       "      <td>2.586872</td>\n",
       "      <td>0.764607</td>\n",
       "      <td>2.145875</td>\n",
       "      <td>0.820506</td>\n",
       "      <td>1.989888</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.234794</td>\n",
       "      <td>1.437346</td>\n",
       "      <td>1.008933</td>\n",
       "      <td>1.308139</td>\n",
       "      <td>0.480702</td>\n",
       "      <td>-0.121228</td>\n",
       "      <td>-0.063869</td>\n",
       "      <td>0.771022</td>\n",
       "      <td>0.448013</td>\n",
       "      <td>-0.640405</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.706527</td>\n",
       "      <td>-0.978673</td>\n",
       "      <td>-0.417671</td>\n",
       "      <td>-0.795302</td>\n",
       "      <td>0.100167</td>\n",
       "      <td>0.114909</td>\n",
       "      <td>-0.161035</td>\n",
       "      <td>-0.297702</td>\n",
       "      <td>-0.054134</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.197109</td>\n",
       "      <td>1.260783</td>\n",
       "      <td>-0.170482</td>\n",
       "      <td>0.098767</td>\n",
       "      <td>-0.179320</td>\n",
       "      <td>-0.301121</td>\n",
       "      <td>-0.512889</td>\n",
       "      <td>0.059712</td>\n",
       "      <td>-0.383929</td>\n",
       "      <td>0.073097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.701692</td>\n",
       "      <td>0.754678</td>\n",
       "      <td>0.180323</td>\n",
       "      <td>-0.009341</td>\n",
       "      <td>0.625712</td>\n",
       "      <td>0.792283</td>\n",
       "      <td>0.867172</td>\n",
       "      <td>1.107332</td>\n",
       "      <td>-0.999713</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.759653</td>\n",
       "      <td>-0.246070</td>\n",
       "      <td>-0.533620</td>\n",
       "      <td>-0.111510</td>\n",
       "      <td>-0.827913</td>\n",
       "      <td>0.023760</td>\n",
       "      <td>0.036641</td>\n",
       "      <td>0.965798</td>\n",
       "      <td>-0.207766</td>\n",
       "      <td>1.060108</td>\n",
       "      <td>...</td>\n",
       "      <td>1.623161</td>\n",
       "      <td>1.536764</td>\n",
       "      <td>1.247670</td>\n",
       "      <td>1.088329</td>\n",
       "      <td>1.324566</td>\n",
       "      <td>1.185399</td>\n",
       "      <td>0.976763</td>\n",
       "      <td>0.713426</td>\n",
       "      <td>1.064480</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.860033</td>\n",
       "      <td>-0.837759</td>\n",
       "      <td>-0.739429</td>\n",
       "      <td>-0.833392</td>\n",
       "      <td>-0.602023</td>\n",
       "      <td>-0.510427</td>\n",
       "      <td>1.127371</td>\n",
       "      <td>0.222923</td>\n",
       "      <td>-1.085397</td>\n",
       "      <td>0.687006</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099189</td>\n",
       "      <td>0.449002</td>\n",
       "      <td>-0.219521</td>\n",
       "      <td>0.602244</td>\n",
       "      <td>-0.377621</td>\n",
       "      <td>0.468178</td>\n",
       "      <td>-0.542571</td>\n",
       "      <td>-0.125260</td>\n",
       "      <td>1.064480</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>-1.436723</td>\n",
       "      <td>-2.100658</td>\n",
       "      <td>-0.767483</td>\n",
       "      <td>-0.855929</td>\n",
       "      <td>-0.706228</td>\n",
       "      <td>-0.527513</td>\n",
       "      <td>1.455122</td>\n",
       "      <td>-0.643885</td>\n",
       "      <td>-0.570320</td>\n",
       "      <td>1.974283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.769471</td>\n",
       "      <td>0.430378</td>\n",
       "      <td>1.195098</td>\n",
       "      <td>1.060460</td>\n",
       "      <td>1.056291</td>\n",
       "      <td>0.756143</td>\n",
       "      <td>0.449139</td>\n",
       "      <td>-0.058941</td>\n",
       "      <td>1.116249</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>0.554841</td>\n",
       "      <td>1.268870</td>\n",
       "      <td>-0.566612</td>\n",
       "      <td>-0.687122</td>\n",
       "      <td>0.916683</td>\n",
       "      <td>0.178024</td>\n",
       "      <td>-0.911653</td>\n",
       "      <td>0.078186</td>\n",
       "      <td>-0.096613</td>\n",
       "      <td>-0.401085</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.745365</td>\n",
       "      <td>-0.340897</td>\n",
       "      <td>-1.005855</td>\n",
       "      <td>-0.646983</td>\n",
       "      <td>-0.668912</td>\n",
       "      <td>0.073945</td>\n",
       "      <td>-1.266200</td>\n",
       "      <td>-1.154135</td>\n",
       "      <td>-0.308101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>0.118178</td>\n",
       "      <td>1.698822</td>\n",
       "      <td>-0.393572</td>\n",
       "      <td>-0.534317</td>\n",
       "      <td>-1.587601</td>\n",
       "      <td>-0.714485</td>\n",
       "      <td>-0.542659</td>\n",
       "      <td>0.935667</td>\n",
       "      <td>-0.681928</td>\n",
       "      <td>-0.030955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155411</td>\n",
       "      <td>0.561964</td>\n",
       "      <td>-0.928590</td>\n",
       "      <td>-1.031806</td>\n",
       "      <td>0.085088</td>\n",
       "      <td>0.874690</td>\n",
       "      <td>-0.732181</td>\n",
       "      <td>-0.704035</td>\n",
       "      <td>0.658741</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>-1.313636</td>\n",
       "      <td>0.941352</td>\n",
       "      <td>-0.846709</td>\n",
       "      <td>-0.945629</td>\n",
       "      <td>-1.162882</td>\n",
       "      <td>-0.539840</td>\n",
       "      <td>-1.043026</td>\n",
       "      <td>0.072626</td>\n",
       "      <td>-0.243226</td>\n",
       "      <td>1.654693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176320</td>\n",
       "      <td>0.251005</td>\n",
       "      <td>-0.730440</td>\n",
       "      <td>-1.264087</td>\n",
       "      <td>0.066208</td>\n",
       "      <td>0.146189</td>\n",
       "      <td>-0.482484</td>\n",
       "      <td>-0.738659</td>\n",
       "      <td>-0.054134</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>-0.549972</td>\n",
       "      <td>0.125926</td>\n",
       "      <td>-0.465391</td>\n",
       "      <td>-0.509300</td>\n",
       "      <td>-0.259827</td>\n",
       "      <td>-0.206049</td>\n",
       "      <td>-0.731390</td>\n",
       "      <td>-0.118205</td>\n",
       "      <td>-0.464623</td>\n",
       "      <td>0.065665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206524</td>\n",
       "      <td>-0.325431</td>\n",
       "      <td>0.204749</td>\n",
       "      <td>-0.679052</td>\n",
       "      <td>1.040887</td>\n",
       "      <td>0.724116</td>\n",
       "      <td>0.023961</td>\n",
       "      <td>-0.720933</td>\n",
       "      <td>0.352698</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1225 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      medIncome  pctWWage  perCapInc  whitePerCap  blackPerCap  indianPerCap  \\\n",
       "0      0.876345  1.600432   0.941602     1.159390     0.415994     -0.093158   \n",
       "1      1.234794  1.437346   1.008933     1.308139     0.480702     -0.121228   \n",
       "2     -0.197109  1.260783  -0.170482     0.098767    -0.179320     -0.301121   \n",
       "3     -0.759653 -0.246070  -0.533620    -0.111510    -0.827913      0.023760   \n",
       "4     -0.860033 -0.837759  -0.739429    -0.833392    -0.602023     -0.510427   \n",
       "...         ...       ...        ...          ...          ...           ...   \n",
       "1585  -1.436723 -2.100658  -0.767483    -0.855929    -0.706228     -0.527513   \n",
       "1588   0.554841  1.268870  -0.566612    -0.687122     0.916683      0.178024   \n",
       "1589   0.118178  1.698822  -0.393572    -0.534317    -1.587601     -0.714485   \n",
       "1591  -1.313636  0.941352  -0.846709    -0.945629    -1.162882     -0.539840   \n",
       "1592  -0.549972  0.125926  -0.465391    -0.509300    -0.259827     -0.206049   \n",
       "\n",
       "      asianPerCap  otherPerCap  HispPerCap  pctPopUnderPov  ...  \\\n",
       "0        0.039099     0.835051    0.563030       -0.420409  ...   \n",
       "1       -0.063869     0.771022    0.448013       -0.640405  ...   \n",
       "2       -0.512889     0.059712   -0.383929        0.073097  ...   \n",
       "3        0.036641     0.965798   -0.207766        1.060108  ...   \n",
       "4        1.127371     0.222923   -1.085397        0.687006  ...   \n",
       "...           ...          ...         ...             ...  ...   \n",
       "1585     1.455122    -0.643885   -0.570320        1.974283  ...   \n",
       "1588    -0.911653     0.078186   -0.096613       -0.401085  ...   \n",
       "1589    -0.542659     0.935667   -0.681928       -0.030955  ...   \n",
       "1591    -1.043026     0.072626   -0.243226        1.654693  ...   \n",
       "1592    -0.731390    -0.118205   -0.464623        0.065665  ...   \n",
       "\n",
       "      Log_burglaries  Log_burglPerPop  Log_larcenies  Log_larcPerPop  \\\n",
       "0           2.256699         1.014704       1.968360        0.007233   \n",
       "1          -0.706527        -0.978673      -0.417671       -0.795302   \n",
       "2           0.701692         0.754678       0.180323       -0.009341   \n",
       "3           1.623161         1.536764       1.247670        1.088329   \n",
       "4          -0.099189         0.449002      -0.219521        0.602244   \n",
       "...              ...              ...            ...             ...   \n",
       "1585        0.769471         0.430378       1.195098        1.060460   \n",
       "1588       -0.745365        -0.340897      -1.005855       -0.646983   \n",
       "1589        0.155411         0.561964      -0.928590       -1.031806   \n",
       "1591        0.176320         0.251005      -0.730440       -1.264087   \n",
       "1592        0.206524        -0.325431       0.204749       -0.679052   \n",
       "\n",
       "      Log_autoTheft  Log_autoTheftPerPop  Log_arsons  Log_arsonsPerPop  \\\n",
       "0          2.586872             0.764607    2.145875          0.820506   \n",
       "1          0.100167             0.114909   -0.161035         -0.297702   \n",
       "2          0.625712             0.792283    0.867172          1.107332   \n",
       "3          1.324566             1.185399    0.976763          0.713426   \n",
       "4         -0.377621             0.468178   -0.542571         -0.125260   \n",
       "...             ...                  ...         ...               ...   \n",
       "1585       1.056291             0.756143    0.449139         -0.058941   \n",
       "1588      -0.668912             0.073945   -1.266200         -1.154135   \n",
       "1589       0.085088             0.874690   -0.732181         -0.704035   \n",
       "1591       0.066208             0.146189   -0.482484         -0.738659   \n",
       "1592       1.040887             0.724116    0.023961         -0.720933   \n",
       "\n",
       "      Log_ViolentCrimesPerPop  isViolentCrimePerPopHigh  \n",
       "0                    1.989888                         1  \n",
       "1                   -0.054134                         0  \n",
       "2                   -0.999713                         0  \n",
       "3                    1.064480                         1  \n",
       "4                    1.064480                         1  \n",
       "...                       ...                       ...  \n",
       "1585                 1.116249                         1  \n",
       "1588                -0.308101                         0  \n",
       "1589                 0.658741                         1  \n",
       "1591                -0.054134                         0  \n",
       "1592                 0.352698                         1  \n",
       "\n",
       "[1225 rows x 44 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Features and Label and set train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df_new.drop(['isViolentCrimePerPopHigh','Log_ViolentCrimesPerPop'], axis=1)\n",
    "y = df_new['isViolentCrimePerPopHigh']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 424)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate and test random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7346938775510204\n"
     ]
    }
   ],
   "source": [
    " # create classifier\n",
    "rf_classifier = RandomForestClassifier() \n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_classifier.predict(X_test)\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7272890843662536\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "clf = RandomForestClassifier()\n",
    " #Initialize with whatever parameters you want to\n",
    "\n",
    "print(np.mean(cross_val_score(clf, X, y, cv=10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate and test random forest tuned with random search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [50, 71, 92, 114, 135, 157, 178, 200], 'max_features': ['auto', 'sqrt'], 'max_depth': [5, 9, 13, 17, 21, 25, 30, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 50, stop = 200, num = 8)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5, 30, num = 7)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   19.5s finished\n"
     ]
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 10 fold cross validation, \n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 10, verbose=2, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X, y)\n",
    "y_pred_best = rf_random.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best features for random forest are: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 5, 'bootstrap': True}\n",
      "R2 score: 0.7918367346938775\n",
      "Improvement from untuned random forest: 0.40816326530611624 %\n"
     ]
    }
   ],
   "source": [
    "print('best features for random forest are:', rf_random.best_params_)\n",
    "print(\"R2 score:\", metrics.accuracy_score(y_test,y_pred_best))\n",
    "print(\"Improvement from untuned random forest:\", (metrics.accuracy_score(y_test,y_pred_best) - metrics.accuracy_score(y_test,y_pred_rf)) * 100,'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   15.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   16.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   15.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   13.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   11.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   11.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   15.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   15.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   15.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   15.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7444022391043583\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print(np.mean(cross_val_score(rf_random, X, y, cv=10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate and test Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7428571428571429"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagging_classifier = BaggingClassifier() \n",
    "bagging_classifier.fit(X_train, y_train)\n",
    "y_pred_bg = bagging_classifier.predict(X_test)\n",
    "metrics.accuracy_score(y_test,y_pred_bg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.704411568705851\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(cross_val_score(BaggingClassifier(), X, y, cv=10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate and test XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7510204081632653"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_classifier = xgb.XGBClassifier(learning_rate = 0.01,)\n",
    "xg_classifier.fit(X_train,y_train)\n",
    "y_pred_xg = xg_classifier.predict(X_test)\n",
    "metrics.accuracy_score(y_test,y_pred_xg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7167199786751965\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(cross_val_score(xg_classifier, X, y, cv=10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate and test LightGBM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7918367346938775"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGBM_clf = LGBMClassifier()\n",
    "LGBM_clf.fit(X_train,y_train)\n",
    "y_pred_lgbm = LGBM_clf.predict(X_test)\n",
    "metrics.accuracy_score(y_test,y_pred_lgbm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6905371184859389\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(cross_val_score(LGBMClassifier(), X, y, cv=10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate and and test AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6979591836734694"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_clf = AdaBoostClassifier()\n",
    "ada_clf.fit(X_train,y_train)\n",
    "y_pred_ada = ada_clf.predict(X_test)\n",
    "metrics.accuracy_score(y_test,y_pred_ada)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6807676929228308\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(cross_val_score(AdaBoostClassifier(), X, y, cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
